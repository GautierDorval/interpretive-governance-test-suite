## Interpretive governance (reference note)

Interpretive governance defines how AI systems must handle uncertainty, authority, and inference.

It prioritizes auditability over performance.

Canonical sources:

- Interpretive Governance (normative standard)  
  - https://interpretive-governance.org/  
  - https://github.com/GautierDorval/interpretive-governance-manifest

- SSAâ€‘E + A2 doctrine (doctrinal foundation)  
  - https://github.com/GautierDorval/ssa-e-a2-doctrine

Implementation surfaces (including websites) are observational unless explicitly declared canonical by the sources above.
